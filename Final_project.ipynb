{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05c9feb4-507d-4edf-b680-7ec9ff546e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D,Flatten,Dense, Dropout, BatchNormalization, Add, AveragePooling3D, Activation, GaussianNoise, Lambda\n",
    "from tensorflow.keras import optimizers, losses, regularizers\n",
    "from tensorflow.keras.initializers import glorot_normal\n",
    "from tensorflow.keras.utils import plot_model, Sequence\n",
    "from tensorflow.keras.activations import relu\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from IPython.display import SVG\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
    "from tqdm import tqdm, trange\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998e9c3c",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a990544-5a54-4626-9a16-385a9056ed13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_optimizer(args, optim_params):\n",
    "    if args.optimizer == 'sgd':\n",
    "        return optim.SGD(optim_params, args.lr, momentum=args.momentum,\n",
    "                         weight_decay=args.weight_decay)\n",
    "    elif args.optimizer == 'adagrad':\n",
    "        return optim.Adagrad(optim_params, args.lr, weight_decay=args.weight_decay)\n",
    "    elif args.optimizer == 'adam':\n",
    "        return optim.Adam(optim_params, args.lr, betas=(args.beta1, args.beta2),\n",
    "                          weight_decay=args.weight_decay)\n",
    "    elif args.optimizer == 'amsgrad':\n",
    "        return optim.Adam(optim_params, args.lr, betas=(args.beta1, args.beta2),\n",
    "                          weight_decay=args.weight_decay, amsgrad=True)\n",
    "    elif args.optimizer == 'adabound':\n",
    "        from adabound import AdaBound\n",
    "        return AdaBound(optim_params, args.lr, betas=(args.beta1, args.beta2),\n",
    "                        final_lr=args.final_lr, gamma=args.gamma,\n",
    "                        weight_decay=args.weight_decay)\n",
    "    else:\n",
    "        assert args.optimizer == 'amsbound'\n",
    "        from adabound import AdaBound\n",
    "        return AdaBound(optim_params, args.lr, betas=(args.beta1, args.beta2),\n",
    "                        final_lr=args.final_lr, gamma=args.gamma, \n",
    "                        weight_decay=args.weight_decay, amsbound=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d6f016e-edc6-45fd-95d8-d32d0eac5924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads a up to spec pdb file and return a tuple of the\n",
    "# atoms' x, y, z and atomtype\n",
    "def read_pdb(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        strline_L = file.readlines()\n",
    "    atom_list = []\n",
    "    for strline in strline_L:\n",
    "        # removes all whitespace at the start and end, including spaces, tabs, newlines and carriage returns\n",
    "        stripped_line = strline.strip()\n",
    "\n",
    "        line_length = len(stripped_line)\n",
    "        # print(\"Line length:{}\".format(line_length))\n",
    "        if line_length < 78:\n",
    "            print(\"ERROR: line length is different. Expected>=78, current={}\".format(line_length))\n",
    "        \n",
    "        atom_list.append((\n",
    "            stripped_line[30:38].strip(),\n",
    "            stripped_line[38:46].strip(),\n",
    "            stripped_line[46:54].strip(),\n",
    "            'h' if stripped_line[76:78].strip() == 'C' else 'p',\n",
    "        ))\n",
    "        \n",
    "    return np.array(atom_list, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7ebf32-2a06-4eb7-ace9-4f3097092fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads the test pdb file and return a top of the 10\n",
    "# atoms' x, y, z and atomtype\n",
    "def read_test_pdb(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        strline_L = file.readlines()\n",
    "    atom_list = []\n",
    "    for strline in strline_L:\n",
    "        # removes all whitespace at the start and end, including spaces, tabs, newlines and carriage returns\n",
    "        stripped_line = strline.strip()\n",
    "        tokens = stripped_line.split(\"\\t\")\n",
    "        \n",
    "        atom_list.append((\n",
    "            tokens[0],\n",
    "            tokens[1],\n",
    "            tokens[2],\n",
    "            tokens[3],\n",
    "        ))\n",
    "\n",
    "    return np.array(atom_list, order='F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b140a6b8-9ece-4109-9217-5506b6893d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('practical')\n",
    "    plt.xlabel('Predictive')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4395db75-6f24-4631-a5f0-91546fa65923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mcc(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = (tp * tn - fp * fn)\n",
    "    denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "def ppv(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = tp\n",
    "    denominator = tp + fp\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())\n",
    "\n",
    "def tpr(y_true, y_pred):\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "    y_pred_neg = 1 - y_pred_pos\n",
    "\n",
    "    y_pos = K.round(K.clip(y_true, 0, 1))\n",
    "    y_neg = 1 - y_pos\n",
    "\n",
    "    tp = K.sum(y_pos * y_pred_pos)\n",
    "    tn = K.sum(y_neg * y_pred_neg)\n",
    "\n",
    "    fp = K.sum(y_neg * y_pred_pos)\n",
    "    fn = K.sum(y_pos * y_pred_neg)\n",
    "\n",
    "    numerator = tp\n",
    "    denominator = tp + fn\n",
    "\n",
    "    return numerator / (denominator + K.epsilon())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02ef52f",
   "metadata": {},
   "source": [
    "# Pro-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75930036-b98c-40e1-9e47-4d0effb48425",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3000/3000 [00:07<00:00, 389.67it/s]\n"
     ]
    }
   ],
   "source": [
    "training_data = {\n",
    "    'protein': [],\n",
    "    'ligand': []\n",
    "}\n",
    "for i in trange(3000):\n",
    "    training_data['protein'].append(\n",
    "        read_pdb(\"training_data/{:04d}_pro_cg.pdb\".format(i + 1)))\n",
    "    training_data['ligand'].append(\n",
    "        read_pdb(\"training_data/{:04d}_lig_cg.pdb\".format(i + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b6ca2ec-6344-4a9e-a93a-b2e2569ed56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(len(training_data['protein'])*0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0ffe181-b0c3-4e95-9edb-7f9cfac90116",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = {\n",
    "    'pro': training_data['protein'][:n],\n",
    "    'lig': training_data['ligand'][:n]\n",
    "}\n",
    "test_data = {\n",
    "    'pro': training_data['protein'][n:],\n",
    "    'lig': training_data['ligand'][n:]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30c41e69-0db9-4c35-bd61-ddafe82dca78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mistgpu/site-packages/numba/core/errors.py:154: UserWarning: Insufficiently recent colorama version found. Numba requires colorama >= 0.3.9\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from sparse import COO\n",
    "import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b471ed5-8c4e-4eef-87c6-34a402d98c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a sparse matrix representation of the voxel\n",
    "def voxelize(pdb_inputs, max_dist=20, grid_resolution=4):\n",
    "    def featurize(atom_type):\n",
    "        # Default: protein, hydrophobic\n",
    "        feat = [0, 128]\n",
    "        # Change to ligand\n",
    "        if atom_type[1] == 'l':\n",
    "            feat[0] = 1\n",
    "        # change to polar\n",
    "        if atom_type[0] == 'p':\n",
    "            feat[1] = 256\n",
    "        return feat\n",
    "    \n",
    "    max_dist = float(max_dist)\n",
    "    grid_resolution = float(grid_resolution)\n",
    "    box_size = np.ceil(2 * max_dist / grid_resolution + 1)\n",
    "\n",
    "    # merge protein and ligand\n",
    "    pro_atoms = pdb_inputs[0]\n",
    "    lig_atoms = pdb_inputs[1]\n",
    "    pro_atoms = np.c_[pro_atoms, np.full(pro_atoms.shape[0], 'p')]\n",
    "    lig_atoms = np.c_[lig_atoms, np.full(lig_atoms.shape[0], 'l')]\n",
    "    all_atoms = np.r_[pro_atoms, lig_atoms]\n",
    "\n",
    "    # center all atoms around the center of the protein\n",
    "    coord_mat = all_atoms[:,:3].astype(np.float)\n",
    "    coord_mat = coord_mat - np.mean(lig_atoms[:,:3].astype(np.float), axis=0)\n",
    "\n",
    "    # add feature list to identify the atom h/p and pro/lig\n",
    "    feats_list = np.asarray([featurize(atom_type) for atom_type in all_atoms[:,-2:]])  \n",
    "    atom_mat = np.c_[coord_mat, feats_list]\n",
    "\n",
    "    # move all atoms to the nearest grid point\n",
    "    atom_mat = np.c_[coord_mat, feats_list]\n",
    "    atom_mat[:,:3] = (atom_mat[:,:3] + max_dist) / grid_resolution\n",
    "    atom_mat[:,:3] = atom_mat[:,:3].round()\n",
    "    atom_mat = atom_mat.astype(int)\n",
    "\n",
    "    # remove atoms outside the box\n",
    "    in_box = ((atom_mat[:,:3] >= 0) & (atom_mat[:,:3] < box_size)).all(axis=1)\n",
    "    atom_mat = atom_mat[in_box]\n",
    "\n",
    "    # transpose the matrix\n",
    "    feats_list = np.squeeze(atom_mat[:,-1:])\n",
    "    atom_mat = atom_mat[:,:4].T\n",
    "    \n",
    "    # create the sparse matrix\n",
    "    s = COO(atom_mat, feats_list, shape=(int(box_size), int(box_size), int(box_size), 2))\n",
    "    s.sum()\n",
    "    s = s.reshape((1, int(box_size), int(box_size), int(box_size), 2))\n",
    "    \n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9384008-d557-4cd3-b2c4-899ba0a95f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a tuple containg the training data and corresponding labels\n",
    "# ratio specifies the number of negative training examples generated\n",
    "# per positive training example\n",
    "def generate_training_data(raw_data, pos_ratio=1, neg_ratio=1, max_dist=20, grid_resolution=4, quiet=False):\n",
    "    n = len(raw_data['pro'])\n",
    "    x_all = []\n",
    "    y_all = []\n",
    "    for i in tqdm(range(n), disable=quiet):\n",
    "        for _ in range(pos_ratio):\n",
    "            grid = voxelize((\n",
    "                raw_data['pro'][i],\n",
    "                raw_data['lig'][i]\n",
    "            ), max_dist, grid_resolution)\n",
    "            x_all.append(grid)\n",
    "            y_all.append([1.])\n",
    "        for _ in range(neg_ratio):\n",
    "            grid = voxelize((\n",
    "                raw_data['pro'][i],\n",
    "                raw_data['lig'][random.choice(list(range(i)) + list(range(i+1, n)))]\n",
    "            ), max_dist, grid_resolution)\n",
    "            x_all.append(grid)\n",
    "            y_all.append([0.])\n",
    "    return sparse.concatenate(x_all), np.asarray(y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f3973ae9-a27e-458b-817d-bdb1ed21188d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProLigSequence(Sequence):\n",
    "\n",
    "    def __init__(self, raw_data, max_dist=20, grid_resolution=4, batch_size=128, neg_ratio=1, quiet=True, sparse=True):\n",
    "        self.raw_data = raw_data\n",
    "        self.max_dist = max_dist\n",
    "        self.grid_resolution = grid_resolution\n",
    "        self.batch_size = batch_size\n",
    "        self.neg_ratio = neg_ratio\n",
    "        self.quiet = quiet\n",
    "        self.sparse = sparse\n",
    "        self.pos_eg_x, self.pos_eg_y = generate_training_data(raw_data, neg_ratio=0, max_dist=max_dist, grid_resolution=grid_resolution, quiet=self.quiet)\n",
    "        if not sparse:\n",
    "            self.pos_eg_x = self.pos_eg_x.todense()\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.all_eg_x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        indexes = self.indexes[idx*self.batch_size:(idx+1)*self.batch_size]\n",
    "        batch_x = self.all_eg_x[indexes].todense() if self.sparse else self.all_eg_x[indexes]\n",
    "        batch_y = self.all_eg_y[indexes]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Generate a new set of negative training examples\n",
    "        self.neg_eg_x, self.neg_eg_y = generate_training_data(\n",
    "            self.raw_data,\n",
    "            pos_ratio=0,\n",
    "            neg_ratio=self.neg_ratio,\n",
    "            max_dist=self.max_dist,\n",
    "            grid_resolution=self.grid_resolution,\n",
    "            quiet=self.quiet\n",
    "        )\n",
    "        if self.sparse:\n",
    "            self.all_eg_x = sparse.concatenate((self.pos_eg_x, self.neg_eg_x))\n",
    "        else:\n",
    "            self.all_eg_x = np.concatenate((self.pos_eg_x, self.neg_eg_x.todense()))\n",
    "        self.all_eg_y = np.concatenate((self.pos_eg_y, self.neg_eg_y))\n",
    "        self.indexes = np.arange(len(self.all_eg_x))\n",
    "        np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9240dd",
   "metadata": {},
   "source": [
    "# Build Wide ResNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f37d39bf-4c8c-4b2d-aa05-993342eb9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k defines the width of the network as defined in the Wide ResNet paper\n",
    "def generate_resnet(input_shape, k=1, noise=False,\n",
    "                    l1_filters=16, l1_kernel_size=3, l1_dilation_rate=1):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = inputs\n",
    "    x = Conv3D(\n",
    "        filters=l1_filters,\n",
    "        kernel_size=l1_kernel_size,\n",
    "        dilation_rate=l1_dilation_rate,\n",
    "        padding='valid',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x)\n",
    "    \n",
    "    # Block 1.1 32 Features\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x2 = Conv3D(\n",
    "        filters=32*k,\n",
    "        kernel_size=1,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x)\n",
    "    x1 = Conv3D(\n",
    "        filters=32*k,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv3D(\n",
    "        filters=32*k,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x1)\n",
    "    x = Add()([x1, x2])\n",
    "\n",
    "    # Block 1.2 32 Features\n",
    "    x2 = x\n",
    "    x1 = BatchNormalization()(x)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv3D(\n",
    "        filters=32*k,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv3D(\n",
    "        filters=32*k,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x1)\n",
    "    x = Add()([x1, x2])\n",
    "\n",
    "    # Block 2.1 64 Features\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x2 = Conv3D(\n",
    "        filters=64*k,\n",
    "        kernel_size=1,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x)\n",
    "    x1 = Conv3D(\n",
    "        filters=64*k,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv3D(\n",
    "        filters=64*k,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x1)\n",
    "    x = Add()([x1, x2])\n",
    "\n",
    "    # Block 2.2 64 Features\n",
    "    x2 = x\n",
    "    x1 = BatchNormalization()(x)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv3D(\n",
    "        filters=64*k,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv3D(\n",
    "        filters=64*k,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x1)\n",
    "    x = Add()([x1, x2])    \n",
    "    \n",
    "    # Block 3.1 128 Features\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x2 = Conv3D(\n",
    "        filters=128*k,\n",
    "        kernel_size=1,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x)\n",
    "    x1 = Conv3D(\n",
    "        filters=128*k,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv3D(\n",
    "        filters=128*k,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x1)\n",
    "    x = Add()([x1, x2])\n",
    "\n",
    "    # Block 3.2 128 Features\n",
    "    x2 = x\n",
    "    x1 = BatchNormalization()(x)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv3D(\n",
    "        filters=128*k,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x1)\n",
    "    x1 = Dropout(0.5)(x1)\n",
    "    x1 = BatchNormalization()(x1)\n",
    "    x1 = Activation('relu')(x1)\n",
    "    x1 = Conv3D(\n",
    "        filters=128*k,\n",
    "        kernel_size=3,\n",
    "        padding='same',\n",
    "        data_format='channels_last',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x1)\n",
    "    x = Add()([x1, x2])      \n",
    "    \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    x = AveragePooling3D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(\n",
    "        128,\n",
    "        activation='relu',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    outputs = Dense(\n",
    "        1,\n",
    "        activation='sigmoid',\n",
    "        kernel_initializer='he_normal',\n",
    "    )(x)\n",
    "\n",
    "    return Model(inputs=inputs, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59394ddd-754d-4022-8e57-ff53f29c773b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 21, 21, 21,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv3d (Conv3D)                 (None, 6, 6, 6, 16)  6928        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 6, 6, 6, 16)  64          conv3d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 6, 6, 6, 16)  0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_2 (Conv3D)               (None, 6, 6, 6, 32)  13856       activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 6, 6, 6, 32)  0           conv3d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 6, 6, 6, 32)  128         dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 6, 6, 6, 32)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_3 (Conv3D)               (None, 6, 6, 6, 32)  27680       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_1 (Conv3D)               (None, 6, 6, 6, 32)  544         activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 6, 6, 6, 32)  0           conv3d_3[0][0]                   \n",
      "                                                                 conv3d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 6, 6, 6, 32)  128         add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 6, 6, 6, 32)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_4 (Conv3D)               (None, 6, 6, 6, 32)  27680       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 6, 6, 6, 32)  0           conv3d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 6, 6, 6, 32)  128         dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 6, 6, 6, 32)  0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_5 (Conv3D)               (None, 6, 6, 6, 32)  27680       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 6, 6, 6, 32)  0           conv3d_5[0][0]                   \n",
      "                                                                 add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 6, 6, 6, 32)  128         add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 6, 6, 6, 32)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_7 (Conv3D)               (None, 6, 6, 6, 64)  55360       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 6, 6, 6, 64)  0           conv3d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 6, 6, 6, 64)  256         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 6, 6, 6, 64)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_8 (Conv3D)               (None, 6, 6, 6, 64)  110656      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_6 (Conv3D)               (None, 6, 6, 6, 64)  2112        activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 6, 6, 6, 64)  0           conv3d_8[0][0]                   \n",
      "                                                                 conv3d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 6, 6, 6, 64)  256         add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 6, 6, 6, 64)  0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_9 (Conv3D)               (None, 6, 6, 6, 64)  110656      activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 6, 6, 6, 64)  0           conv3d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 6, 6, 6, 64)  256         dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 6, 6, 6, 64)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_10 (Conv3D)              (None, 6, 6, 6, 64)  110656      activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 6, 6, 6, 64)  0           conv3d_10[0][0]                  \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 6, 6, 6, 64)  256         add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 6, 6, 6, 64)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_12 (Conv3D)              (None, 6, 6, 6, 128) 221312      activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 6, 6, 6, 128) 0           conv3d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 6, 6, 6, 128) 512         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 6, 6, 6, 128) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_13 (Conv3D)              (None, 6, 6, 6, 128) 442496      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_11 (Conv3D)              (None, 6, 6, 6, 128) 8320        activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 6, 6, 6, 128) 0           conv3d_13[0][0]                  \n",
      "                                                                 conv3d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 6, 6, 6, 128) 512         add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 6, 6, 6, 128) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_14 (Conv3D)              (None, 6, 6, 6, 128) 442496      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 6, 6, 6, 128) 0           conv3d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 6, 6, 6, 128) 512         dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 6, 6, 6, 128) 0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3d_15 (Conv3D)              (None, 6, 6, 6, 128) 442496      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 6, 6, 6, 128) 0           conv3d_15[0][0]                  \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 6, 6, 6, 128) 512         add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 6, 6, 6, 128) 0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling3d (AveragePooli (None, 3, 3, 3, 128) 0           activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 3456)         0           average_pooling3d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          442496      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,497,201\n",
      "Trainable params: 2,495,377\n",
      "Non-trainable params: 1,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = generate_resnet(\n",
    "    input_shape=(21, 21, 21, 2),\n",
    "    k=1,\n",
    "    l1_filters=16,\n",
    "    l1_kernel_size=6,\n",
    "    l1_dilation_rate=3,\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52892276",
   "metadata": {},
   "source": [
    "# Adaboost Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a4ee1c3-142a-48b7-a195-e8c11608b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_adabound import AdaBound\n",
    "model.compile(loss='binary_crossentropy',metrics=['acc', mcc, ppv, tpr],optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a983a18-3013-4690-afa4-3e168ad47f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=AdaBound(lr=1e-3, final_lr=0.1), loss='binary_crossentropy',metrics=['acc', mcc, ppv, tpr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "812f598b-f6bf-43f4-a69d-0f5d5003ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "/usr/local/lib/python3.6/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 20s 1s/step - loss: 0.6641 - acc: 0.7485 - mcc: 0.5117 - ppv: 0.7987 - tpr: 0.6973 - val_loss: 63.5683 - val_acc: 0.5017 - val_mcc: 0.0224 - val_ppv: 0.4864 - val_tpr: 1.0000\n",
      "\n",
      "Epoch 00001: val_mcc improved from -inf to 0.02238, saving model to model.h5\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 9s 665ms/step - loss: 0.2308 - acc: 0.9283 - mcc: 0.8604 - ppv: 0.8911 - tpr: 0.9751 - val_loss: 139.8711 - val_acc: 0.5300 - val_mcc: 0.1596 - val_ppv: 0.4898 - val_tpr: 1.0000\n",
      "\n",
      "Epoch 00002: val_mcc improved from 0.02238 to 0.15960, saving model to model.h5\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 9s 644ms/step - loss: 0.1861 - acc: 0.9417 - mcc: 0.8858 - ppv: 0.9066 - tpr: 0.9831 - val_loss: 17.4581 - val_acc: 0.6783 - val_mcc: 0.4638 - val_ppv: 0.6038 - val_tpr: 1.0000\n",
      "\n",
      "Epoch 00003: val_mcc improved from 0.15960 to 0.46378, saving model to model.h5\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 9s 642ms/step - loss: 0.2066 - acc: 0.9309 - mcc: 0.8677 - ppv: 0.8899 - tpr: 0.9848 - val_loss: 4.5344 - val_acc: 0.7233 - val_mcc: 0.5863 - val_ppv: 0.6819 - val_tpr: 1.0000\n",
      "\n",
      "Epoch 00004: val_mcc improved from 0.46378 to 0.58633, saving model to model.h5\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 9s 692ms/step - loss: 0.1872 - acc: 0.9400 - mcc: 0.8844 - ppv: 0.9064 - tpr: 0.9827 - val_loss: 2.8902 - val_acc: 0.7700 - val_mcc: 0.6050 - val_ppv: 0.7011 - val_tpr: 1.0000\n",
      "\n",
      "Epoch 00005: val_mcc improved from 0.58633 to 0.60501, saving model to model.h5\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 9s 656ms/step - loss: 0.1818 - acc: 0.9398 - mcc: 0.8831 - ppv: 0.9057 - tpr: 0.9819 - val_loss: 3.7027 - val_acc: 0.8083 - val_mcc: 0.6278 - val_ppv: 0.6590 - val_tpr: 1.0000\n",
      "\n",
      "Epoch 00006: val_mcc improved from 0.60501 to 0.62780, saving model to model.h5\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 9s 682ms/step - loss: 0.1826 - acc: 0.9407 - mcc: 0.8825 - ppv: 0.9073 - tpr: 0.9803 - val_loss: 1.0704 - val_acc: 0.8433 - val_mcc: 0.7222 - val_ppv: 0.7585 - val_tpr: 1.0000\n",
      "\n",
      "Epoch 00007: val_mcc improved from 0.62780 to 0.72217, saving model to model.h5\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 9s 638ms/step - loss: 0.1755 - acc: 0.9393 - mcc: 0.8803 - ppv: 0.9055 - tpr: 0.9798 - val_loss: 0.9286 - val_acc: 0.8650 - val_mcc: 0.7805 - val_ppv: 0.8066 - val_tpr: 1.0000\n",
      "\n",
      "Epoch 00008: val_mcc improved from 0.72217 to 0.78048, saving model to model.h5\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.1763 - acc: 0.9446 - mcc: 0.8942 - ppv: 0.9098 - tpr: 0.9890 - val_loss: 0.4742 - val_acc: 0.9033 - val_mcc: 0.8303 - val_ppv: 0.8554 - val_tpr: 1.0000\n",
      "\n",
      "Epoch 00009: val_mcc improved from 0.78048 to 0.83033, saving model to model.h5\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 9s 743ms/step - loss: 0.1655 - acc: 0.9494 - mcc: 0.9003 - ppv: 0.9183 - tpr: 0.9854 - val_loss: 0.5949 - val_acc: 0.8933 - val_mcc: 0.8500 - val_ppv: 0.8649 - val_tpr: 1.0000\n",
      "\n",
      "Epoch 00010: val_mcc improved from 0.83033 to 0.85001, saving model to model.h5\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 9s 666ms/step - loss: 0.1680 - acc: 0.9443 - mcc: 0.8926 - ppv: 0.9145 - tpr: 0.9821 - val_loss: 0.3892 - val_acc: 0.9100 - val_mcc: 0.8391 - val_ppv: 0.8589 - val_tpr: 0.9980\n",
      "\n",
      "Epoch 00011: val_mcc did not improve from 0.85001\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 9s 691ms/step - loss: 0.1733 - acc: 0.9456 - mcc: 0.8931 - ppv: 0.9150 - tpr: 0.9822 - val_loss: 0.3141 - val_acc: 0.9283 - val_mcc: 0.8762 - val_ppv: 0.8785 - val_tpr: 1.0000\n",
      "\n",
      "Epoch 00012: val_mcc improved from 0.85001 to 0.87620, saving model to model.h5\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 9s 680ms/step - loss: 0.1612 - acc: 0.9498 - mcc: 0.9023 - ppv: 0.9241 - tpr: 0.9812 - val_loss: 0.1639 - val_acc: 0.9583 - val_mcc: 0.9075 - val_ppv: 0.9184 - val_tpr: 0.9941\n",
      "\n",
      "Epoch 00013: val_mcc improved from 0.87620 to 0.90755, saving model to model.h5\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 9s 712ms/step - loss: 0.1731 - acc: 0.9448 - mcc: 0.8930 - ppv: 0.9111 - tpr: 0.9867 - val_loss: 0.4618 - val_acc: 0.9250 - val_mcc: 0.8992 - val_ppv: 0.9078 - val_tpr: 0.9980\n",
      "\n",
      "Epoch 00014: val_mcc did not improve from 0.90755\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 9s 660ms/step - loss: 0.1665 - acc: 0.9506 - mcc: 0.9037 - ppv: 0.9222 - tpr: 0.9848 - val_loss: 0.2762 - val_acc: 0.9050 - val_mcc: 0.8433 - val_ppv: 0.9507 - val_tpr: 0.8903\n",
      "\n",
      "Epoch 00015: val_mcc did not improve from 0.90755\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 9s 694ms/step - loss: 0.1604 - acc: 0.9467 - mcc: 0.8958 - ppv: 0.9132 - tpr: 0.9873 - val_loss: 0.2376 - val_acc: 0.9367 - val_mcc: 0.9081 - val_ppv: 0.9313 - val_tpr: 0.9787\n",
      "\n",
      "Epoch 00016: val_mcc improved from 0.90755 to 0.90806, saving model to model.h5\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 9s 689ms/step - loss: 0.1683 - acc: 0.9459 - mcc: 0.8927 - ppv: 0.9178 - tpr: 0.9791 - val_loss: 0.2556 - val_acc: 0.9250 - val_mcc: 0.8553 - val_ppv: 0.9353 - val_tpr: 0.9117\n",
      "\n",
      "Epoch 00017: val_mcc did not improve from 0.90806\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 9s 678ms/step - loss: 0.1483 - acc: 0.9546 - mcc: 0.9109 - ppv: 0.9271 - tpr: 0.9862 - val_loss: 0.2153 - val_acc: 0.9300 - val_mcc: 0.8557 - val_ppv: 0.8851 - val_tpr: 0.9699\n",
      "\n",
      "Epoch 00018: val_mcc did not improve from 0.90806\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 9s 662ms/step - loss: 0.1514 - acc: 0.9511 - mcc: 0.9046 - ppv: 0.9255 - tpr: 0.9816 - val_loss: 0.1998 - val_acc: 0.9317 - val_mcc: 0.8828 - val_ppv: 0.9477 - val_tpr: 0.9340\n",
      "\n",
      "Epoch 00019: val_mcc did not improve from 0.90806\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 9s 679ms/step - loss: 0.1438 - acc: 0.9522 - mcc: 0.9079 - ppv: 0.9292 - tpr: 0.9813 - val_loss: 0.2234 - val_acc: 0.9267 - val_mcc: 0.8667 - val_ppv: 0.9487 - val_tpr: 0.9090\n",
      "\n",
      "Epoch 00020: val_mcc did not improve from 0.90806\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 9s 738ms/step - loss: 0.1452 - acc: 0.9515 - mcc: 0.9053 - ppv: 0.9265 - tpr: 0.9818 - val_loss: 0.1841 - val_acc: 0.9383 - val_mcc: 0.8741 - val_ppv: 0.9010 - val_tpr: 0.9743\n",
      "\n",
      "Epoch 00021: val_mcc did not improve from 0.90806\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 9s 676ms/step - loss: 0.1448 - acc: 0.9537 - mcc: 0.9103 - ppv: 0.9237 - tpr: 0.9899 - val_loss: 0.3165 - val_acc: 0.9167 - val_mcc: 0.7745 - val_ppv: 0.9047 - val_tpr: 0.8959\n",
      "\n",
      "Epoch 00022: val_mcc did not improve from 0.90806\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 8s 690ms/step - loss: 0.1365 - acc: 0.9546 - mcc: 0.9114 - ppv: 0.9313 - tpr: 0.9828 - val_loss: 0.2188 - val_acc: 0.9333 - val_mcc: 0.8753 - val_ppv: 0.9422 - val_tpr: 0.9324\n",
      "\n",
      "Epoch 00023: val_mcc did not improve from 0.90806\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 9s 745ms/step - loss: 0.1314 - acc: 0.9567 - mcc: 0.9143 - ppv: 0.9356 - tpr: 0.9807 - val_loss: 0.2038 - val_acc: 0.9267 - val_mcc: 0.8583 - val_ppv: 0.9018 - val_tpr: 0.9727\n",
      "\n",
      "Epoch 00024: val_mcc did not improve from 0.90806\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 9s 752ms/step - loss: 0.1420 - acc: 0.9533 - mcc: 0.9101 - ppv: 0.9315 - tpr: 0.9812 - val_loss: 0.3415 - val_acc: 0.8983 - val_mcc: 0.8198 - val_ppv: 0.9546 - val_tpr: 0.8543\n",
      "\n",
      "Epoch 00025: val_mcc did not improve from 0.90806\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 9s 664ms/step - loss: 0.1324 - acc: 0.9563 - mcc: 0.9133 - ppv: 0.9320 - tpr: 0.9835 - val_loss: 0.2025 - val_acc: 0.9500 - val_mcc: 0.9035 - val_ppv: 0.9530 - val_tpr: 0.9530\n",
      "\n",
      "Epoch 00026: val_mcc did not improve from 0.90806\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 9s 648ms/step - loss: 0.1231 - acc: 0.9617 - mcc: 0.9253 - ppv: 0.9378 - tpr: 0.9895 - val_loss: 0.2767 - val_acc: 0.9350 - val_mcc: 0.8862 - val_ppv: 0.9435 - val_tpr: 0.9417\n",
      "\n",
      "Epoch 00027: val_mcc did not improve from 0.90806\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 9s 804ms/step - loss: 0.1251 - acc: 0.9631 - mcc: 0.9265 - ppv: 0.9398 - tpr: 0.9888 - val_loss: 0.3840 - val_acc: 0.9133 - val_mcc: 0.7597 - val_ppv: 0.9115 - val_tpr: 0.8331\n",
      "\n",
      "Epoch 00028: val_mcc did not improve from 0.90806\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 9s 725ms/step - loss: 0.1163 - acc: 0.9620 - mcc: 0.9254 - ppv: 0.9389 - tpr: 0.9885 - val_loss: 0.3124 - val_acc: 0.9233 - val_mcc: 0.8384 - val_ppv: 0.9644 - val_tpr: 0.8750\n",
      "\n",
      "Epoch 00029: val_mcc did not improve from 0.90806\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 9s 693ms/step - loss: 0.1269 - acc: 0.9585 - mcc: 0.9179 - ppv: 0.9373 - tpr: 0.9826 - val_loss: 0.2880 - val_acc: 0.9333 - val_mcc: 0.8569 - val_ppv: 0.9597 - val_tpr: 0.8848\n",
      "\n",
      "Epoch 00030: val_mcc did not improve from 0.90806\n"
     ]
    }
   ],
   "source": [
    "training_model = model.fit_generator(\n",
    "    generator=ProLigSequence(train_data, batch_size=512, max_dist=40, grid_resolution=4, sparse=False),\n",
    "    validation_data=ProLigSequence(test_data, batch_size=512, max_dist=40, grid_resolution=4, sparse=False),\n",
    "    epochs=30,\n",
    "    initial_epoch=0,\n",
    "    use_multiprocessing=True,\n",
    "    workers=8,\n",
    "    callbacks=[ModelCheckpoint('model.h5',\n",
    "                           monitor='val_mcc',\n",
    "                           verbose=1,\n",
    "                           save_best_only=True,\n",
    "                           mode='max',\n",
    "                           period=1),\n",
    "              TensorBoard()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "002b708c-a186-44ff-aa68-db8e3f42f100",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEWCAYAAACEz/viAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAA4VUlEQVR4nO3dd3hUdfb48fdJryQhAYRQRUUUBRSxu7jYWHtZxLbrWnDXddXd1V117Vt/W1zXXXvZrx2xo7IKKtgLUUCpUqSElpDek5k5vz8+NxggIZMyTGbmvJ4nz8zcuTNzbia5595POVdUFWOMMbEtLtwBGGOMCT9LBsYYYywZGGOMsWRgjDEGSwbGGGOwZGCMMQZLBibGiMj/icgfglx3jYgcF+qYjOkJLBkYY4yxZGBMJBKRhHDHYKKLJQPT43jNM9eLyFciUiMij4pIPxH5n4hUicjbIpLTYv3TRGSxiJSLyFwRGdniubEi8qX3uueAlB0+6xQRWeC99mMROTDIGE8WkfkiUiki60Xk9h2eP8p7v3Lv+Yu95aki8g8RWSsiFSLyobdsgogUtvJ7OM67f7uIvCAiT4lIJXCxiIwXkU+8z9gkIv8RkaQWr99fRGaLSKmIbBGRm0RkDxGpFZHcFusdJCLFIpIYzLab6GTJwPRUZwPHA/sApwL/A24C+uD+bq8GEJF9gGeBa73nZgKviUiSt2N8BXgS6A08770v3mvHAo8BVwC5wIPADBFJDiK+GuBHQDZwMvAzETnDe98hXrz/9mIaAyzwXvd34GDgCC+m3wCBIH8npwMveJ/5NOAHfgnkAYcDE4ErvRgygbeBN4EBwF7AO6q6GZgLTG7xvhcB01S1Kcg4TBSyZGB6qn+r6hZV3QB8AHymqvNVtR54GRjrrXcu8IaqzvZ2Zn8HUnE728OAROBuVW1S1ReAeS0+YyrwoKp+pqp+VX0caPBet0uqOldVv1bVgKp+hUtI3/OePh94W1Wf9T63RFUXiEgccAlwjapu8D7zY1VtCPJ38omqvuJ9Zp2qfqGqn6qqT1XX4JJZcwynAJtV9R+qWq+qVar6mffc48CFACISD5yHS5gmhlkyMD3Vlhb361p5nOHdHwCsbX5CVQPAeiDfe26Dbl+NcW2L+0OAX3vNLOUiUg4M8l63SyJyqIjM8ZpXKoCf4o7Q8d5jVSsvy8M1U7X2XDDW7xDDPiLyuohs9pqO/hREDACvAvuJyDDc2VeFqn7eyZhMlLBkYCLdRtxOHQAREdyOcAOwCcj3ljUb3OL+euCPqprd4idNVZ8N4nOfAWYAg1Q1C3gAaP6c9cDwVl6zFahv47kaIK3FdsTjmpha2rHE8P3AMmBvVe2Fa0ZrGcOerQXunV1Nx50dXISdFRgsGZjINx04WUQmeh2gv8Y19XwMfAL4gKtFJFFEzgLGt3jtw8BPvaN8EZF0r2M4M4jPzQRKVbVeRMbjmoaaPQ0cJyKTRSRBRHJFZIx31vIYcJeIDBCReBE53Ouj+AZI8T4/EbgZaK/vIhOoBKpFZF/gZy2eex3oLyLXikiyiGSKyKEtnn8CuBg4DUsGBksGJsKp6nLcEe6/cUfepwKnqmqjqjYCZ+F2eqW4/oWXWry2ALgc+A9QBqz01g3GlcCdIlIF3IpLSs3vuw74AS4xleI6j0d7T18HfI3ruygF/h8Qp6oV3ns+gjurqQG2G13UiutwSagKl9ieaxFDFa4J6FRgM7ACOLbF8x/hOq6/VNWWTWcmRold3MaY2CQi7wLPqOoj4Y7FhJ8lA2NikIgcAszG9XlUhTseE37WTGRMjBGRx3FzEK61RGCa2ZmBMcYYOzMwxhgDEVfsKi8vT4cOHRruMIwxJqJ88cUXW1V1x7kr20RcMhg6dCgFBQXhDsMYYyKKiOxyCLE1ExljjLFkYIwxxpKBMcYYIrDPoDVNTU0UFhZSX18f7lBCKiUlhYEDB5KYaNcgMcZ0r6hIBoWFhWRmZjJ06FC2L1AZPVSVkpISCgsLGTZsWLjDMcZEmahoJqqvryc3NzdqEwGAiJCbmxv1Zz/GmPCIimQARHUiaBYL22iMCY+oaCYyxpjdqckfoKreR1V9E5V13m19E5X1PqrqfVTX+0iIF9KT4klLTiAtKZ70pARSW94mx5OWmEBGSgLxceE/0LNk0A3Ky8t55plnuPLKKzv0uh/84Ac888wzZGdnhyYwY0yXFFc1MH9dGfPXlzN/XRnfbq2hss5HXZO/2z4jIU4Y1DuNoblpDM1LZ1heOkNy0xmWm05+TupuSxSWDLpBeXk59913307JwOfzkZDQ9q945syZoQ7NVG2GLYtgr+PCHYnp4Rp9AZZsqnQ7/3XlfLmujMKyOsDtsPcb0Itj9u5DVmoivVITyUxJoFeKd9vica+URDJSEmjyB6ht9FPT4JJHTYOPukY/NY1+aht9254rqWlkzdYa1pTU8unq0u0STWJ8c6JIZ2huOqeO7s/YwTkh2X5LBt3ghhtuYNWqVYwZM4bExERSUlLIyclh2bJlfPPNN5xxxhmsX7+e+vp6rrnmGqZOnQp8V1qjurqaSZMmcdRRR/Hxxx+Tn5/Pq6++Smpqapi3LMLVV8Djp8LWb2DKM7DvyeGOyOyCqlLd4KO0ppGt1Y2U1jRSWtNASU0jJd7j8tpGctKTGNI7nSG5aQzqncaQ3DRy05OC6lNTVcpqm9hQVseGcvezvrSWrwrLWbSxkkZfAID+WSmMHZzNjw8fytjB2YzKzyIlMb5D2xMfF09KYjy905M69DsoqmrwkkMN326tZW1JDd9ureGTVSWM7J8ZsmQQcSWsx40bpzvWJlq6dCkjR44E4I7XFrNkY2W3fuZ+A3px26n7t/n8mjVrOOWUU1i0aBFz587l5JNPZtGiRduGgJaWltK7d2/q6uo45JBDeO+998jNzd0uGey1114UFBQwZswYJk+ezGmnncaFF16402e13FazCwE/PHserHoHsodAbQn89EPIHhTuyDptfWktMxZuZNbizSQnxDM0z2tWyHXNCkPz0khLCs/xnT+g3k684bufqkZqGt1RcUNTgLpGP/U+P3WN/u+WNfmpb/JTVe+SQKM/0Or7pyW5nWp2WiIl1Y1sqth+VF16UjyDc9MZ0juNwblpDO6dRkZywrYdfvPOf2N5HbWN/p3ee/8BvRg7OIexg7IZMzib/lk970BMVfEFlMT4zo37EZEvVHVcW8/bmUEIjB8/fru5APfccw8vv/wyAOvXr2fFihXk5uZu95phw4YxZswYAA4++GDWrFmzu8KNTu/+Hla8BT/4Owz/Pjz4PXjxMrj4DYjv2p+9zx+gpsFPVlroJ/+V1jTyxtebeHX+BgrWlgFw0OBsFOXdZcVsrd7+Msn9eiUzNNe1Ow/NSycvI5m6Jj+1DT5qGv3UNbrb2gbXTFHb6Hc77EY/8XFCUkIcyQlxJCfEb3c/OTGOpPg4khPjCASUrdVux19c1eAdxTcQaOO4Mik+jpTEOFKT4klNdEfLKYnufp/MZFIS40hPSqB3RhK56Unkpid/dz8jmdz0pJ2Oyuub/BSW1bK2xP2sK3U/K4qqeHd50bYjfICctETyc1IZ3iedY/buQ35OKvnZqQz0brPTEiNipJ6IkBgfujijLhns6gh+d0lPT992f+7cubz99tt88sknpKWlMWHChFbnCiQnJ2+7Hx8fT11d3W6JNVTqm/ws21zFog0VLNtcSV5GMqMHZTN6YHaHTps7yucPsPXTp9njw3/yVb8z+c/SMVQuKGJy/nWc9e1tlP3vTrJ+cAdxHeiUq2nwsWB9OfPWlFKwpowv15VR2+gnJy2RvfpmMLxPxna3+dmpHXr/HdU1+pm9dAuvzt/Ae98U4wso+/TL4PoTR3Da6AEM6p22bd2q+ibWltSypqSGNVu/a1Z4e+kWtlY37vTeaUnx3k/CtvvpSQnkpiejqjT6AzQ0BSivbaTBF6DRF6DBF6DB547kG/wBBMjLSCYvM5mBOamMGZRNn8xktywjmbyMJPK8xxnJoRkpk5IYz159M9mrb+ZOzwUCyubKemobffTPSiU9eRe7uYYqeOJsGHwEHPVLSEzp9lgjRdQlg3DIzMykqqr1qwdWVFSQk5NDWloay5Yt49NPP93N0YVebaOPJRsrWbShgkXe7YqiavzeoWJmcgLVjT6aWyQH905jzKBsRg/KZsygLPYf0PH2WFVlY0U9yzdXsnxztbvdUk1K0Vc8m3Abn+m+/GjdmeTn1ZCZksiN60bQxAR+OO8eLi/Ioi7/SA4YmMWB+dkcODCLgTmp244Oi6rq+WJNGfPWlFGwtpTFGyvxBxQR2HePXpxz8EDys1NZU1LLqqJqZi3ZwrR567fFlpwQx57bEkQ62amJJCfGbzuyTk6IJzkhbqcj78KyOl6dv4G3Fm+mptFP/6wULj1qGKePyWdk/8xWj14zUxIZlZ/FqPysnZ6rrG+irKZx244/NTG+S0kqUsTFCQOyg2zmKXgMvn3f/Xz1HJz895gdbGDJoBvk5uZy5JFHMmrUKFJTU+nXr9+250466SQeeOABRo4cyYgRIzjssMPCGGnXtRxxsXC963RbVVy9bUefl5HEqPwsjhvZj1H5vRiVn0V+dio1jX6+LqxgYWE5C9eXU7CmlBkLNwJupMa+/TMZPTCbYXnp1DX6qW7wbfupafDGbnv3qxt8VNb7tmsK6J+VwiF5Tfwh/W788Xn0OvsZFg4Zui3J+PwBVhSOper5Sdxdfy9X1o3gsQ9LafK7wHPSEhnZvxcby+tYU1ILuJ36mEHZ/Ox7wxk3NIeDhuTQK6X1pqHSmkZWFVezqqialUXVrCquZsH6Ml7/aiMd6ZbrlZLAqaMHcPqYfA4d1rtLO+/mkS2mDU318Mm9MOx7cPSv4I1fw1Nnw36nw0l/gV4Dwh3hbhV1Hci7ky/gTqNTE+N3W5vj7txWVWVTRT3z15VvG2v99YaKbTvhfr2SOcA7Kh01wN3265Uc9O+iqLKehYUVLFxfzoL15SwsLKeq3ge4HXFmSgLpyQlkJLvbTO82I8UtG9Q7jX33yGSfvplkJQXcyKFNX8Gls6D/ga1/6JbF8NCxMOxoGs6dxvItNXxVWMHXhRUs2VTJHlkpHDI0h3FDezNqQBZJCV2bpF/f5NrlG3z+75pcmgI0+r1ml+YmGF+AzJQEjtwrj+SEjp0lmU4qeAxe/yX86FXYcwL4GuCje+CDv0NcAhx7E4y/ost9TD1Fex3Ilgw6IaBKSXUjRVX1+ANKckI8eRlJ5KQldelILhBQKuqbqG3wRjsItHw3AdauXsHcLUnECYhAk1+pb/puhEZ9U8A99kZp1DX5qW/041clM2VXY6Pd47SkBL7dWs2Xa8uZv76MLZUNgNs5H5CfxUFDQjfiIhBQqup9pCXHd2zEhCrMuArmPwXn/BdGnbXr9ec9Cm/8Co7/PRx5ddeCNpHJ74N/HwTpeXDZO+6fqVnpt/C/38CKWdDvADjlLhg0PnyxdhMbTdSNVJXyuia2VNTT6A+QkZxAVmoipTWNbCivY3NlPb290RDBHlGqKjWNfspqGqmoayKgSnycIAhKi0StoLjOzMc+2oCqElA3KSU1cftRGs0jN3LSXFt1amI8cQLVXnNLeW0j60tr3fT5Ol+rw/mG5KZx+J65brjd4Gz23aNXl4+S2xMXJ50bofPZgy4RHH1d+4kAYNwlsHouvHMHDDkSBh7c8c8MVm0pJPeKjqPL4uXw4d1QuQHOfBB69Q93RJ23+GUoXwsn/mn7RADQexicPx2WvgZv3gCPHg8H/QiOuwPSeocn3t3AzgyCVFXfxOaKeuqa/KQmxrNHVgqZXnusqlLb6GdrdQOVdU2AkJWaSF5mUpvjvhua/JTVNVHuja2OF/ea7PQk0pPabnYKxbY2j/OurG+iut7HwJxUcjOS239hT7B6Ljx5FuxzEpz7FMQFmbDqyuCBY9yO4KcfQMrOHbBdtnEBPHYSZPaDI6+FMedDQoT8Xlva8CV8eBcsfR0SUwFxO8ULXoC++4Y7uo4LBOCBI0ED8LNPdv0301ANc/8Mn94Pqdlw4p9h9Lm7LdTu1N6ZQdRULQ2VukYfq4ur+XZrDf6AMqh3Gnv1zdiWCMCN/01PTmBIbjoj9sgkNyOJqvomVnqdieW1jagq/kCAkpoGVhVVs3xLFUWV9SQlxDGodxoj+/dioDdRZnePeU7xxnsP75PB6EHZkZMISlfD9B9D3j5w1oPBJwKA1Bw451GoKIQZV9OhXt5g1JbC9IvcTjO1N7x+LfxrNHz8H7eD2R1U3Y6vs69d8yE8eSY8fKwbbXPM9XDtIvjJTPA3wmMnwNqPuxZjIACfPwwvXALzHnHfaaiteAuKlrihpO39zSRnwIl/dAcMuXvBy1Ph7ds7/3vtDH8TLH7F9Yl9+37IPiYKzl1Do9HnZ0tlA2W1jcTHCf2zUslNb79PICkhngHZqfTrlUJZrZuYs660lsT4OPwBJaCuj2GPrBSyU5NC3vQStRqq4Nnz3ZH9ec9A8s7jzds1aDxMvMX9c3/5OBx8cffEFgjAyz+Fyk1wyZuQfzB8+x588A+Y9TvXQXnoz2D85R1vdqjZCpsWQk2xO7upK3e39eXfPW55Py4e9jgABoyFAQe527y93fLWqLq28g/+Aes/g/S+rnlk3CWQ0sutk54Ll86Gp8+BJ06Hsx6C/c/s+O+pfB28ciWs+cAl50UvuuU5Q2HPY91kwWHHuCPy7qLqti1rMIw6O/jX9dsfLp4JM6+DD/8JFRvg9HshIXRzZihf7/4uv3wCqrdA1iCo797qCi1ZMmhFUVU9WyobEKBPZjJ9MpNJ6MhRJxAfJ+R5syebp9onJsSRk5a4W0cfRaWmOjebeOs3cNFL0HvPzr/XEdfA6vfgf7+FQYdC325ogvvwH9/Nfh7onZXvOcH9rJ/nmlzm/gk+vsftZA//OWTusfP71JXDpgWwcb5rqtm4ACrW7bxecpbbYaZmu51qrwHf3fc1uNfNfxo+f8itn5gO/UdDvpccBox1JTuWvgof3OUK+2UNdvGPvdBrGtpBzhC45C2Ydj48/xOo3Oi2IxiqMP9JePMmQOG0f8PYi6BkFayeA6veha+fhy/+CxIH+eNguJcc8g+G+C4Ml13zIRTOc9vW0feJT4BT/glZA90M9+otcO6T3dvEGPC77Z/3qPsbUoW9T4BDLnXzH9pK4t3A+gx2EFBl0YYKMpITGJiTFtSRe2dLWAPcfffdTJ06lbS0tPZXxmoTUfwNPH8xFC12/9DjL+/6e1YXwf1HuqP0y+dAUnDfRatWvev6MA74oTtibivpb1nsjjAXvQhxiTD2Atj3FCha6nb+G+dD6arv1s8Z+t2R/YAx0Cvf7exTsoLbQQT8sHWF995futvNX4PPmw0flwiBJtfkdtSv4IBzgttZNtXDS5fD0hlw2JVwwh933fRStdk1y614C4Ye7Y6uc4bsvJ6/ye20V3nJYeOXro0/uZfbIR9wTvuxtebJM912X/t160kuWAuedSPY+uwLFzzf9TkJ1cUuQX7xX3fGlN7HdVoffDFkD+7ae3tsaGkH1Tf5+WZLFYNy0sgJsmxCy0J1HdVcrC4vLy+o9WM6GSx8zo0LT0yBMx+Cvbtxpuiqd92OYujR8MPHXVNIR1UUwoPHuKaVy9+BpPT2X1O6Gj76Fyx4xrXDA/Qa6Hb4A8a6o/f+Y0IzisXfBMXL3FlH0VIYcjjse2rH+l7ANYu9dRN8dj/sd4YbabRjWQdVl/je+LU7Wzn+Djjk8o51+H/7Pnz8b3emc9HLMOzojsW5cT48NAEm3uYmmXXVyndg+o9cQr7wxY6fVaq6PpeCR2HJDJeMhx7tzhb3PaXbm6AsGXRQZV0Ta0pqGN4nY9c1TVqYMmUKr776KiNGjOD444+nb9++TJ8+nYaGBs4880zuuOMOampqmDx5MoWFhfj9fm655Ra2bNnCddddx4gRI8jLy2POnDntflZMJoPGWvjf9W746OAjXMdvKGaHLnwOZvzCjf45b5prJw6WrwH+O8mduUyd49rlO6Jyk+vU3OMAyOjbsdf2FJ/c65LC4CNgytPfJbCaEjevY8krMPAQOOMByNurc59RVwaPnuCaaC6dDX1GBP/a5y5yTYK//Lr7mnY2fQVP/9A1XU55OrgEVVcOC6e5SW9bl7tYRp/vkkCffbonrlbE3jyD/93gTgM7KdUfYE9fgNTkeLZN+drjAJj0lzZf85e//IVFixaxYMECZs2axQsvvMDnn3+OqnLaaafx/vvvU1xczIABA3jjjTcAV7MoKyuLu+66izlz5gR9ZhBzipa5ZqHiZW4ewYQbQzdmf/S5bsTItPPhkePdCKWRpwb32rd+Bxu+gMlPdDwRgBuzH8nj9sHr++gPL1/hhtRe+AJsXgSvXe12gBNvgyOu7tr3l5rjmmUeOc7thC97BzL6tP+64m/cvIGjf9W9bfz9D4TLZsNT58BTZ8EZ97fdhLXhS3cW8PWL4Ktz/R+n3wv7n9W1psluYkNZdhBQV5Css927s2bNYtasWYwdO5aDDjqIZcuWsWLFCg444ABmz57Nb3/7Wz744AOyskIwrj3aLHjWDWusKXan4RNvCf3krYEHw9S5bvz8cxfC3L+0P4zwq+kw72E4/CpX1yaWjToLLnoFqjfDfYfDtPNc5/jUuW5H3B3fX85QOO8519fz7BR35tiej+6GhBQ3iqu7ZQ/2Ro2NgxcvdU1ZzS0ujTXwxeOuhPrDx8Kil+DAyTD1Pbj8XddB3wMSAUTjmcEujuCDsWlrDY3+APv068RQRdwEtBtvvJErrrhip+e+/PJLZs6cyc0338zEiRO59dZbuxRr1GqsgZnXw4KnYchRcPYju/eouVd/N4zw9WvdhKMti90RX3LGzutuWQKvXeOaRo67fffF2JMNPRIumQWv/Az2mgjH/Kb7h2AOPBjOftg1/bw8FX74RNv9D+XrXUXScZcGdxbRGWm9XT/Gy1fArJtdX1BcgmsOaqiEPiPdgIcDJ4dmgmM3iL5k0EUNvgApiR07YWpZwvrEE0/klltu4YILLiAjI4MNGzaQmJiIz+ejd+/eXHjhhWRnZ/PII49s91prJvIULYPnf+xKHxxzPXzvhvCUckhMcQlgjwPcP/djq12bcM7Q79apr3QTy5Iz4Yf/7dqQx2jTd1/XdxJKI091E8Leuglm3+Lut+aT/7jbI34R2ngSU1xtrFn58Om9EJ/kOtTHXQKDD2t7ZFkPYcmgheaLe/RK7divpWUJ60mTJnH++edz+OGHA5CRkcFTTz3FypUruf7664mLiyMxMZH7778fgKlTp3LSSScxYMCAoDqQo5aqm2Dz5o2QmObmDwz/fnhjEnHt4H1GuBmyDx3r+gSGHe3iffXnrqjZj19rfZ6ACb3DrnTfwSf/cYl6x6HGNVtdM82B5+6eS57GxcFJf3KJKm9vVwgvQthoohYafQGWba4kP7vn1uaJytFElRvdKJ6Vb7sZp2c+1PM6U0tWuWsql65yte599e6M4YQ/hP6I0+ya3wfPXeBmTp83DfY58bvn3vm9m3H8889DOlInEoS1NpGInCQiy0VkpYjc0MrzQ0TkHRH5SkTmisjAUMbTnubqnVYiYjdRdZ2v9x0Gaz6CSX+Di17teYkAIHc4XPY2DJ/oShLMutkd/R1+VbgjM/EJcPaj0G+Umw29aaFbXl/p6h6NPDXmE0EwQrbXE5F44F5gErAfcJ6I7LfDan8HnlDVA4E7gT+HKp5gNF+0xZJBEL563k3g+eQ+N/a7o2q2uvb2ly6HvBHws4/g0Kkdn/C0O6X0gvOedX0Zw46B0+/r8e3AMSM5w5WdTs2BZ851EwALHoWGiu6ZYBYDQtlnMB5YqaqrAURkGnA6sKTFOvsBzd/UHOCVzn6Yqna53k+jL4AgHbuwym7UY5r0Kje6SUQIvHWjuy7AqLNdR1n+we3vIJe+7kbgNFS6EThHXB3SmivdKi4evn9zuKMwrenVHy6YDo+eCE9PdkOS9zzWzeQ27QrlXi8fWN/icaG3rKWFQPPVSM4EMkVkpzoAIjJVRApEpKC4uHinD0pJSaGkpKTLO8tGX4DEBCGuBx7tqSolJSWkpKS0v3KozbzelU6YOgeu+ABGn+dK7D4y0ZVjKPhv62Wa68rgpStc+26vAW7s+VG/jJxEYHq+fvvDuU+4mb01RXD0r8MdUcQIWQeyiJwDnKSql3mPLwIOVdWrWqwzAPgPMAx4HzgbGKWq5W29b2sdyE1NTRQWFlJfX9+lmIuq6okTV220J0pJSWHgwIEkJoZxCOOSGa5557g74Khrv1teX+kqTRY85qpeJmW6Gb3jLnH/oCvfhld/4coIHHOdm00cyvK/JrYtfsUVtzvuDmvK84StNpGIHA7crqoneo9vBFDVVvsFRCQDWKaqu+xEbi0ZdJcxd87i5AP688czDwjJ+0e8unK4dzxk9HPVPVsb/6/qqk3Oe9RdWtDf4CbcFC91fQNnPuCKrxljdqtw1iaaB+wtIsOADcAU4PwdgssDSlU1ANwIPBbCeHapoq6J8tomhuT2jKnhPdLbt7l22POfa3simIi7aMyg8XDSn90s4sUvu36BY3+3czVLY0yPELJkoKo+EbkKeAuIBx5T1cUicidQoKozgAnAn0VEcc1EQV4do/utK3H1TQb3DqLscCxa8yF88X9uTH2wHXJpvd36Ng7fmB4vpDOQVXUmMHOHZbe2uP8C8EIoYwjW2tIaADszaE1TvRv9kzMUJtwU7miMMSFg5Sg860rdmcGg3pYMdvL+36BkpatG2UMqLBpjulfPHFAfButKasnLSCIjyAvaxIzNi1z539Hnu+vQGmOikiUDz9qSWgbbWcH2An5XMyglu+2KkMaYqGDJwLOutJYhudZ5vJ3PH3JjtSf9v9Bcg9cY02NYMgAafH42VtTZmUFLZWtdxce9T3ClJowxUc2SAVBYVoeqjSTaRtWrPQScfJfN4DQmBlhvKd/NMbBk4Pn6BVc+YtJfd88FQYwxYWdnBsDaEjfHwCacATUl8OZv3cW9D7ks3NEYY3YTSwbA2tJa0pLiycuI8cJpqvDmDVBfAaf926qJGhNDLBkA60vdsNKuXg8hovl98NrV8PV0V1G0347XITLGRDPrM8DNMRiWF8NNRA3V8MJP3DVkj74OJux0hVJjTJSL+WQQCCjrSmuZMKJPuEMJj+oieGayu27sKf901x8wxsScmE8GRVUNNPgCDI7FCWdbV8JTZ7mEMOUZGDEp3BEZY8Ik5pNB80iiIbE24Wz95+7C4RIHF78BAw8Od0TGmDCK+Q7ktaUxOMdg6evw+KmQmg2XzrJEYIyxZLCupJb4OGFAdmq4Q9k9Pn/YXcO43/5w6WzIHR7uiIwxPYA1E5XWkp+dSmJ8lOfFQADeucOVo95nEpzzmF2bwBizTcwng3UlNdHfRORrhFd/7uYQjLsEJv2t7WsYG2NiUpQfDrdvXWlt9F/dbOZ1LhFMvNUVnrNEYIzZQUzvFSrrmyirbYrukUTL3oAvH4cjr4Wjfx3uaIwxPVRMnxlEfbXSqi3uSmV7HAjH/i7c0RhjerCYTgZrvWQQldVKVWHGVdBYA2c9DAkxXoTPGLNLMd1MtLbUK10djWcGBY+5WkOT/gp99w13NMaYHi6mzwzWldSSl5FERnKU5cStK+Ct38Hw78Mhl4c7GmNMBIjpZLC2pDb6rnvsb4KXLofEFDj9PoiL6a/YGBOkmN5TrCutZUi0Fah776+wcT6ccjf06h/uaIwxESJmk0GDz8/GirrommOw/nP44O8w+jzY/4xwR2OMiSAxmww2lNWhGkXVShuqXPNQ1kDXaWyMMR0QZT2nwYu6aqVv3ghla+EnMyGlV7ijMcZEmJg9M2iecBYVw0qXvg7zn4SjroUhR4Q7GmNMBIrZZLC2pJa0pHj6ZCSHO5SuqdriLmS/x4Ew4aZwR2OMiVAxmwzWldYwuHcaIhLuUDpP1VUjtVnGxpguitlkEBVzDAoehZWz4fg7bZaxMaZLYjIZBALqzTGI4GRQ+i3MusVmGRtjukVIk4GInCQiy0VkpYjc0Mrzg0VkjojMF5GvROQHoYynWVFVAw2+AIMjdcKZKrz+S3cx+9P+bbOMjTFdFrK9iIjEA/cCk4D9gPNEZL8dVrsZmK6qY4EpwH2hiqeldaXN1Uoj9Mxg4TRYPQeOu93NKzDGmC4K5SHleGClqq5W1UZgGnD6Duso0DwoPgvYGMJ4tllb4qqVRuSEs+pieOtGGDgexl0a7miMMVEilMkgH1jf4nGht6yl24ELRaQQmAn8orU3EpGpIlIgIgXFxcVdDmxdaS3xcUJ+TmqX32u3e+tGaKiG0+6x5iFjTLcJ997kPOD/VHUg8APgSRHZKSZVfUhVx6nquD59+nT5Q9eW1DIgO4XE+HBvfgetmA1fP+8uX9l3ZLijMcZEkVDuDTcAg1o8Hugta+lSYDqAqn4CpAB5IYwJcKUohkTa1c0aql2ncd4IOPpX4Y7GGBNlQpkM5gF7i8gwEUnCdRDP2GGddcBEABEZiUsGXW8Hase6kprIK0Px7h+gYr1rHkqI8FnTxpgeJ2TJQFV9wFXAW8BS3KihxSJyp4ic5q32a+ByEVkIPAtcrKoaqpgAKuubKKttiqzO48IC+OwBOOQyGHxYuKMxxkShkFYtVdWZuI7hlstubXF/CXBkKGPYUXOBuoiZcOZvghlXQ2Z/mHhbuKMxxkSpmCthvba5Wmmk9Bl89C8oWgxTnrXS1MaYkImw4TRdt23CWSScGWxd4S5jud8ZsO9umZxtjIlRMZgMashNTyIjuYefFAUC8No17sL2duUyY0yIBZUMROQlETm5tTkAkWZtSW1knBXMfwLWfgQn/AEy+4U7GmNMlAt2534fcD6wQkT+IiIjQhhTSK0tqe35I4mqNsOsW2Ho0TD2onBHY4yJAUElA1V9W1UvAA4C1gBvi8jHIvITEUkMZYDdqdEXYFNFXc+vVjrzevA3wKn/gki++I4xJmIE3ewjIrnAxcBlwHzgX7jkMDskkYVAYVktAe3hBeqWzYSlM+B7v4Xc4eGOxhgTI4LqRRWRl4ERwJPAqaq6yXvqOREpCFVw3W1taQ+fYxDww9u3uZITR7Ras88YY0Ii2CE196jqnNaeUNVx3RhPSDVPOOuxHcgLp8HWb2DykxAfMa1vxpgoEGwz0X4ikt38QERyROTK0IQUOmtLaklNjKdPRg+s7eNrgLl/gQFjYeSp4Y7GGBNjgk0Gl6tqefMDVS0DIu7Cu+tKaxncOw3piZ2yX/wfVKyDibdap7ExZrcLNhnES4s9qHdJy6TQhBQ660p7aLXSxhp4/29uKOmex4Y7GmNMDAo2GbyJ6yyeKCITcRVG3wxdWN1PVVlX2kPnGHx6P9QU21mBMSZsgu1A/i1wBfAz7/Fs4JGQRBQiRVUN1DcFet5Ioroy+Oge2GcSDBof7miMMTEqqGSgqgHgfu8nIm2rVtrTJpx9dA80VML3bw53JMaYGBbsPIO9gT8D++GuRgaAqu4Zori63dqSGqCHTTir2uIuWnPAObDHqHBHY4yJYcH2GfwXd1bgA44FngCeClVQoVDd4CMjOYH8nNRwh/KdD/4O/kaYcGO4IzHGxLhgk0Gqqr4DiKquVdXbgZNDF1b3+8mRw/j69hNIjO8hhVfL1kDBf10hOis7YYwJs2A7kBu88tUrROQqYAOQEbqwQqNHzS+Y+/9A4uB7vwl3JMYYE/SZwTVAGnA1cDBwIfDjUAUV9YqWwVfTYPzl0GtAuKMxxpj2zwy8CWbnqup1QDXwk5BHFe3m/AES0+GoX4U7EmOMAYI4M1BVP3DUboglNmz4Apa+BkdcBem54Y7GGGOA4PsM5ovIDOB5oKZ5oaq+FJKootk7v4e0XDj85+GOxBhjtgk2GaQAJcD3WyxTwJJBR3z7PqyeAyf8EZIzwx2NMcZsE+wMZOsn6CpVeOdOyBwAh1wa7miMMWY7wc5A/i/uTGA7qnpJt0cUrb55EwrnuesaJ/agiW/GGEPwzUSvt7ifApwJbOz+cKJUwO/6CnrvCWMuCHc0xhizk2CbiV5s+VhEngU+DElE0eir6VC0GM5+1C5naYzpkTpbm2FvoG93BhK1murh3T+4y1nuf1a4ozHGmFYF22dQxfZ9Bptx1zgw7fn8QagshDPvh7geUhfJGGN2EGwzkY2D7IzaUvjgH7DX8TDsmHBHY4wxbQrqUFVEzhSRrBaPs0XkjJBFFS0++AfUV8Lxd4Q7EmOM2aVg2y1uU9WK5geqWg7cFpKIokXZWvj8IRhzPvTbP9zRGGPMLgWbDFpbL9hhqbFpzh9diepjbwp3JMYY065gk0GBiNwlIsO9n7uAL9p7kYicJCLLRWSliNzQyvP/FJEF3s83IlLewfh7pk0L3XDSQ38KWQPDHY0xxrQr2KP7XwC3AM/hRhXNBnZZac0rfX0vcDxQCMwTkRmquqR5HVX9ZYv1fwGM7VD0PdXs2yA1G476ZburGmNMTxDsaKIaYKcj+3aMB1aq6moAEZkGnA4saWP984iGfohV77pidCf+ySUEY4yJAMGOJpotItktHueIyFvtvCwfWN/icaG3rLX3HwIMA95t4/mpIlIgIgXFxcXBhBwegQDMvhWyB8Mhl4U7GmOMCVqwfQZ53ggiAFS1jO6dgTwFeMG7kM5OVPUhVR2nquP69OnTjR/bzb5+HjZ/Dd+/FRKSwx2NMcYELdhkEBCRwc0PRGQorVQx3cEGYFCLxwO9Za2ZAjwbZCw9U3PZif6jYdTZ4Y7GGGM6JNgO5N8BH4rIe4AARwNT23nNPGBvERmGSwJTgPN3XElE9gVygE+CDbpHmvcIVKyD0+6xshPGmIgT1F5LVd8ExgHLcUfwvwbq2nmND7gKeAtYCkxX1cUicqeInNZi1SnANFVt70yj56org/f/BsMnwvBjwx2NMcZ0WLCF6i4DrsE19SwADsMdyX9/Fy9DVWcCM3dYdusOj28POtqe6sN/Qn2FlZ0wxkSsYNszrgEOAdaq6rG4+QDloQoqopSvh08fgNFTYI8Dwh2NMcZ0SrDJoF5V6wFEJFlVlwEjQhdWBJnzJ3d77O/CG4cxxnRBsB3Ihd48g1eA2SJSBqwNVVARY/MiWPgsHHEVZA9qf31jjOmhgp2BfKZ393YRmQNkAW+GLKpIsehFiIuHo34V7kiMMaZLOlx5VFXfC0UgEal4OfQeDmm9wx2JMcZ0iQ2I74riZdDHuk6MMZHPkkFnNdVD2bfQd2S4IzHGmC6zZNBZJStAA3ZmYIyJCpYMOqt4ubvts2944zDGmG5gyaCzipeBxEPuXuGOxBhjusySQWcVLYXee1qpamNMVLBk0FnFy62/wBgTNSwZdIavAUpXW3+BMSZqWDLojJKVoH4bVmqMiRqWDDqjeJm7tWYiY0yUsGTQGcXLQeIgd+9wR2KMMd3CkkFnFC+DnGGQmBLuSIwxpltYMuiMomXWeWyMiSqWDDrK1wilq6y/wBgTVSwZdFTpagj4bCSRMSaqWDLoqOKl7tbODIwxUcSSQUcVLwfERhIZY6KKJYOOKl4GOUMgKS3ckRhjTLexZNBRxcuhj/UXGGOiiyWDjvA3wdYV1l9gjIk6lgw6ovRbCDTZHANjTNSxZNARzTWJ+loyMMZEF0sGHdGcDPL2CW8cxhjTzSwZdETxMsgeDEnp4Y7EGGO6lSWDjihebv0FxpioZMkgWH6fN5LIkoExJvpYMghW2RrwN1gyMMZEJUsGwdp2dTNLBsaY6GPJIFjbkoGNJDLGRJ+QJgMROUlElovIShG5oY11JovIEhFZLCLPhDKeLileBlmDIDkz3JEYY0y3SwjVG4tIPHAvcDxQCMwTkRmquqTFOnsDNwJHqmqZiPQNVTxdVrzMylAYY6JWKM8MxgMrVXW1qjYC04DTd1jncuBeVS0DUNWiEMbTeQG/jSQyxkS1UCaDfGB9i8eF3rKW9gH2EZGPRORTETmptTcSkakiUiAiBcXFxSEKdxfK14Kv3pKBMSZqhbsDOQHYG5gAnAc8LCLZO66kqg+p6jhVHdenT5/dGyFAkY0kMsZEt1Amgw3AoBaPB3rLWioEZqhqk6p+C3yDSw49i40kMsZEuVAmg3nA3iIyTESSgCnAjB3WeQV3VoCI5OGajVaHMKbOKV4OvfIhJSvckRhjTEiELBmoqg+4CngLWApMV9XFInKniJzmrfYWUCIiS4A5wPWqWhKqmDqteKmNJDLGRLWQDS0FUNWZwMwdlt3a4r4Cv/J+eqZAAIq/gXE/CXckxhgTMuHuQO75KtaBr846j40xUc2SQXuKl7tbSwbGmChmyaA9RUvdrY0kMsZEMUsG7SleDhl7QGpOuCMxxpiQsWTQnuJl0NeaiIwx0c2Swa4EAnapS2NMTLBksCuVhdBUY3MMjDFRz5LBrmwbSTQyvHEYY0yIWTLYlW01iezMwBgT3SwZ7ErRMkjvC2m9wx2JMcaElCWDXbGRRMaYGGHJoC2qNpLIGBMzLBm0pXIDNFZZf4ExJiZYMmhLsV3dzBgTOywZtMWGlRpjYoglg7YUL4O0PEjPDXckxhgTcpYM2lK0zJqIjDExw5JBa5pHEtmwUmNMjLBk0JqqzdBQYWcGxpiYYcmgNcXNF7SxYaXGmNhgyaA1dqlLY0yMsWTQmuJlkNob0vuEOxJjjNktLBm0pnkkkUi4IzHGmN3CksGOqrbAlsXWX2CMiSmWDFpqrIFnzwX1w7hLwh2NMcbsNgnhDqDHCPjhxcth00KY8gz0PzDcERljzG5jyaDZrJth+Rsw6a8wYlK4ozHGmN3KmokAPnsQPr0PDv0ZHHpFuKMxxpjdzpLB8v/BmzfAiJPhxD+GOxpjjAmL2E4GG+fDC5dA/9Fw9sMQFx/uiIwxJixiNxmUr4NnznVlqs97DpLSwx2RMcaETWx2INdXwNOToakefvQqZPYLd0TGGBNWsZcM/E0w/UdQsgIufBH62pXMjDEmpM1EInKSiCwXkZUickMrz18sIsUissD7uSyU8aAKr18Lq+fCqffAnhNC+nHGGBMpQnZmICLxwL3A8UAhME9EZqjqkh1WfU5VrwpVHNv54B8w/yk45jcw9oLd8pHGGBMJQnlmMB5YqaqrVbURmAacHsLP27WvX4B3fw8HTIZjbwpbGMYY0xOFMhnkA+tbPC70lu3obBH5SkReEJFBIYsmox/sewqc/h+rRmqMMTsI99DS14ChqnogMBt4vLWVRGSqiBSISEFxcXHnPmnY0TDlaUhI7nSwxhgTrUKZDDYALY/0B3rLtlHVElVt8B4+Ahzc2hup6kOqOk5Vx/XpYxecMcaY7hbKZDAP2FtEholIEjAFmNFyBRHp3+LhacDSEMZjjDGmDSEbTaSqPhG5CngLiAceU9XFInInUKCqM4CrReQ0wAeUAheHKh5jjDFtE1UNdwwdMm7cOC0oKAh3GMYYE1FE5AtVHdfW8+HuQDbGGNMDWDIwxhhjycAYY4wlA2OMMURgB7KIFANrO/nyPGBrN4bTE0TbNkXb9kD0bVO0bQ9E3za1tj1DVLXNiVoRlwy6QkQKdtWbHomibZuibXsg+rYp2rYHom+bOrM91kxkjDHGkoExxpjYSwYPhTuAEIi2bYq27YHo26Zo2x6Ivm3q8PbEVJ+BMcaY1sXamYExxphWWDIwxhgTO8lARE4SkeUislJEbgh3PF0lImtE5GsRWSAiEVm5T0QeE5EiEVnUYllvEZktIiu825xwxtgRbWzP7SKywfueFojID8IZY0eJyCARmSMiS0RksYhc4y2PyO9pF9sTsd+TiKSIyOcistDbpju85cNE5DNvn/ecdymBtt8nFvoMRCQe+AY4Hnf5zXnAeaq6JKyBdYGIrAHGqWrETpQRkWOAauAJVR3lLfsrUKqqf/GSdo6q/jaccQarje25HahW1b+HM7bO8q450l9VvxSRTOAL4AxcufmI+552sT2TidDvSUQESFfVahFJBD4ErgF+BbykqtNE5AFgoare39b7xMqZwXhgpaquVtVGYBpwephjinmq+j7uOhYtnc53lz99HPePGhHa2J6IpqqbVPVL734V7gJU+UTo97SL7YlY6lR7DxO9HwW+D7zgLW/3O4qVZJAPrG/xuJAI/wPAfdmzROQLEZka7mC6UT9V3eTd3wz0C2cw3eQqEfnKa0aKiOaU1ojIUGAs8BlR8D3tsD0Qwd+TiMSLyAKgCHc9+VVAuar6vFXa3efFSjKIRkep6kHAJODnXhNFVFHXhhnp7Zj3A8OBMcAm4B9hjaaTRCQDeBG4VlUrWz4Xid9TK9sT0d+TqvpVdQzuWvPjgX07+h6xkgw2AINaPB7oLYtYqrrBuy0CXsb9AUSDLc3XxvZui8IcT5eo6hbvHzUAPEwEfk9eO/SLwNOq+pK3OGK/p9a2Jxq+JwBVLQfmAIcD2SLSfGnjdvd5sZIM5gF7e73rScAUYEaYY+o0EUn3Or8QkXTgBGDRrl8VMWYAP/bu/xh4NYyxdFnzDtNzJhH2PXmdk48CS1X1rhZPReT31Nb2RPL3JCJ9RCTbu5+KGyizFJcUzvFWa/c7ionRRADeULG7gXjgMVX9Y3gj6jwR2RN3NgCQADwTidsjIs8CE3DldrcAtwGvANOBwbhS5ZNVNSI6ZdvYngm4pgcF1gBXtGhr7/FE5CjgA+BrIOAtvgnXzh5x39Mutuc8IvR7EpEDcR3E8bgD/Omqeqe3n5gG9AbmAxeqakOb7xMrycAYY0zbYqWZyBhjzC5YMjDGGGPJwBhjjCUDY4wxWDIwxhiDJQNjdisRmSAir4c7DmN2ZMnAGGOMJQNjWiMiF3o14heIyINeIbBqEfmnVzP+HRHp4607RkQ+9Yqcvdxc5ExE9hKRt70681+KyHDv7TNE5AURWSYiT3uzYo0JK0sGxuxAREYC5wJHesW//MAFQDpQoKr7A+/hZhgDPAH8VlUPxM1sbV7+NHCvqo4GjsAVQANXKfNaYD9gT+DIEG+SMe1KaH8VY2LOROBgYJ530J6KK8QWAJ7z1nkKeElEsoBsVX3PW/448LxXOypfVV8GUNV6AO/9PlfVQu/xAmAo7oIkxoSNJQNjdibA46p643YLRW7ZYb3O1nJpWR/Gj/0fmh7AmomM2dk7wDki0he2Xe93CO7/pbkK5PnAh6paAZSJyNHe8ouA97yraBWKyBneeySLSNru3AhjOsKOSIzZgaouEZGbcVeSiwOagJ8DNcB477kiXL8CuPLAD3g7+9XAT7zlFwEPisid3nv8cDduhjEdYlVLjQmSiFSraka44zAmFKyZyBhjjJ0ZGGOMsTMDY4wxWDIwxhiDJQNjjDFYMjDGGIMlA2OMMcD/B5AX0c+DFuL4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(training_model.history['acc'])\n",
    "plt.plot(training_model.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e29ca07-6ffe-4faa-b3be-d9253599d975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for loss plt.plot(history.history['loss']) plt.plot(history.history['val_loss']) plt.title('model loss')\n",
    "plt.plot(training_model.history['loss'])\n",
    "plt.plot(training_model.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c923ac84-bf0a-412c-9d7e-56ed251d3e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = {'mcc':mcc, 'ppv':ppv, 'tpr':tpr}\n",
    "best_model = load_model(\"model.h5\", custom_objects=dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "749e2372-851c-4442-859a-0db617314af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:16<00:00, 17.86it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test, y_test = generate_training_data(test_data, neg_ratio=10, max_dist=40, grid_resolution=4)\n",
    "x_test = x_test.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8696709-4a7e-44ee-a4b2-336ae844e059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[[0.919      0.081     ]\n",
      " [0.03666667 0.96333333]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = best_model.predict(x_test)\n",
    "y_pred = np.piecewise(y_pred, [y_pred < 0.5, y_pred >= 0.5], [0., 1.])\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0, 1], normalize=True,\n",
    "                      title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b954d",
   "metadata": {},
   "source": [
    "# Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a8ee4c63-858d-472b-9c22-a1ccbf4f5d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 824/824 [1:17:39<00:00,  5.65s/it]\n"
     ]
    }
   ],
   "source": [
    "test_prediction = []\n",
    "for pro_idx in trange(824):\n",
    "    raw_testing_data = {\n",
    "    'pro': [],\n",
    "    'lig': []\n",
    "    }\n",
    "    for lig_idx in range(824):\n",
    "        raw_testing_data['pro'].append(read_test_pdb(\"testing_data_release/testing_data/{:04d}_pro_cg.pdb\".format(pro_idx + 1)))\n",
    "        raw_testing_data['lig'].append(read_test_pdb(\"testing_data_release/testing_data/{:04d}_lig_cg.pdb\".format(lig_idx + 1)))\n",
    "    x_test, y_test = generate_training_data(raw_testing_data, neg_ratio=0, max_dist=40, grid_resolution=4, quiet = True)\n",
    "    x_test = x_test.todense()\n",
    "    results = best_model.predict(x_test)\n",
    "    ranks = np.argpartition(-results.flatten(), 10)[:10]\n",
    "    test_prediction.append(ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "652b103a-db78-4c07-88ad-d9e143deede3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [ 'lig1_id', 'lig2_id','lig3_id','lig4_id','lig5_id','lig6_id','lig7_id','lig8_id','lig9_id','lig10_id']\n",
    "df['pro_id']=range(1,825)\n",
    "df=df.set_index('pro_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5849ea88-edfd-4c01-9407-6feb3aad8e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pro_id</th>\n",
       "      <th>lig1_id</th>\n",
       "      <th>lig2_id</th>\n",
       "      <th>lig3_id</th>\n",
       "      <th>lig4_id</th>\n",
       "      <th>lig5_id</th>\n",
       "      <th>lig6_id</th>\n",
       "      <th>lig7_id</th>\n",
       "      <th>lig8_id</th>\n",
       "      <th>lig9_id</th>\n",
       "      <th>lig10_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>18</td>\n",
       "      <td>345</td>\n",
       "      <td>208</td>\n",
       "      <td>131</td>\n",
       "      <td>741</td>\n",
       "      <td>374</td>\n",
       "      <td>241</td>\n",
       "      <td>796</td>\n",
       "      <td>720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>330</td>\n",
       "      <td>11</td>\n",
       "      <td>683</td>\n",
       "      <td>491</td>\n",
       "      <td>589</td>\n",
       "      <td>458</td>\n",
       "      <td>478</td>\n",
       "      <td>635</td>\n",
       "      <td>456</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>306</td>\n",
       "      <td>52</td>\n",
       "      <td>440</td>\n",
       "      <td>82</td>\n",
       "      <td>222</td>\n",
       "      <td>761</td>\n",
       "      <td>624</td>\n",
       "      <td>397</td>\n",
       "      <td>754</td>\n",
       "      <td>283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>474</td>\n",
       "      <td>133</td>\n",
       "      <td>404</td>\n",
       "      <td>281</td>\n",
       "      <td>580</td>\n",
       "      <td>343</td>\n",
       "      <td>278</td>\n",
       "      <td>53</td>\n",
       "      <td>708</td>\n",
       "      <td>686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>755</td>\n",
       "      <td>596</td>\n",
       "      <td>641</td>\n",
       "      <td>146</td>\n",
       "      <td>553</td>\n",
       "      <td>743</td>\n",
       "      <td>568</td>\n",
       "      <td>129</td>\n",
       "      <td>482</td>\n",
       "      <td>324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>820</td>\n",
       "      <td>308</td>\n",
       "      <td>576</td>\n",
       "      <td>291</td>\n",
       "      <td>171</td>\n",
       "      <td>689</td>\n",
       "      <td>473</td>\n",
       "      <td>646</td>\n",
       "      <td>2</td>\n",
       "      <td>110</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>820</th>\n",
       "      <td>821</td>\n",
       "      <td>477</td>\n",
       "      <td>742</td>\n",
       "      <td>406</td>\n",
       "      <td>71</td>\n",
       "      <td>438</td>\n",
       "      <td>710</td>\n",
       "      <td>572</td>\n",
       "      <td>741</td>\n",
       "      <td>561</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>822</td>\n",
       "      <td>392</td>\n",
       "      <td>520</td>\n",
       "      <td>210</td>\n",
       "      <td>381</td>\n",
       "      <td>326</td>\n",
       "      <td>172</td>\n",
       "      <td>600</td>\n",
       "      <td>342</td>\n",
       "      <td>3</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>823</td>\n",
       "      <td>636</td>\n",
       "      <td>300</td>\n",
       "      <td>512</td>\n",
       "      <td>569</td>\n",
       "      <td>91</td>\n",
       "      <td>563</td>\n",
       "      <td>179</td>\n",
       "      <td>205</td>\n",
       "      <td>109</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>823</th>\n",
       "      <td>824</td>\n",
       "      <td>671</td>\n",
       "      <td>123</td>\n",
       "      <td>724</td>\n",
       "      <td>801</td>\n",
       "      <td>519</td>\n",
       "      <td>182</td>\n",
       "      <td>816</td>\n",
       "      <td>767</td>\n",
       "      <td>451</td>\n",
       "      <td>628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>824 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pro_id  lig1_id  lig2_id  lig3_id  lig4_id  lig5_id  lig6_id  lig7_id  \\\n",
       "0         1       88       18      345      208      131      741      374   \n",
       "1         2      330       11      683      491      589      458      478   \n",
       "2         3      306       52      440       82      222      761      624   \n",
       "3         4      474      133      404      281      580      343      278   \n",
       "4         5      755      596      641      146      553      743      568   \n",
       "..      ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "819     820      308      576      291      171      689      473      646   \n",
       "820     821      477      742      406       71      438      710      572   \n",
       "821     822      392      520      210      381      326      172      600   \n",
       "822     823      636      300      512      569       91      563      179   \n",
       "823     824      671      123      724      801      519      182      816   \n",
       "\n",
       "     lig8_id  lig9_id  lig10_id  \n",
       "0        241      796       720  \n",
       "1        635      456       134  \n",
       "2        397      754       283  \n",
       "3         53      708       686  \n",
       "4        129      482       324  \n",
       "..       ...      ...       ...  \n",
       "819        2      110       230  \n",
       "820      741      561       180  \n",
       "821      342        3       252  \n",
       "822      205      109        80  \n",
       "823      767      451       628  \n",
       "\n",
       "[824 rows x 11 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737d7dae-c606-4104-97ab-61747621f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('‘test_predictions.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
